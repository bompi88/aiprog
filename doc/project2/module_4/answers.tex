\section{Overall structure and key elements of our Expectimax system}
For this module we started writing in Python, as recommended by the course
staff. However, maybe due to the inherit nature of Python or due to mistakes
done in our first implementation, we got pretty bad results using MiniMax with a depth of 3.
Increasing the depth resulted in really slow running times, and we thought that our heuristic was smart enough to get the job done, as long as the search could go deeper. At this time, we mostly got tiles of 512, but occasionally also tiles of value 1024. This was not good enough.

Therefore we decided to look for faster alternatives, that could potentially process to deeper levels in the same amount of time. We considered Java, but did not want to rewrite our slick GUI. We could also have created a command line application in
Java, as the interface would be fairly simple; just simply providing a maximum depth
and a board, and getting back an integer representing a move in either direction. We feared that the
cost of shelling to CLI application and starting the JVM for every move, would
be a bottleneck.

So in the end we decided to use the built-in Python library ctypes, to interface
with an Expectimax implementation in C. We did not have a ton of experience using
C, so there is probably a lot of additional optimizations that could have been done. Mostly we
ported our Python code line for line. To optimize our implementation we did a mixture of profiling in Valgrind to find
which functions took the most time, and performing plain old compiler optimizations through setting a different GCC optimization flag. By doing this, GCC did a lot of work for us. After those optimizations, we now achieve a depth of 6
in Expectimax, and if we generate only C - instead of 2C - chance successors, the
movements are quite quick, in the order of 200ms. However, since we spent most
of our time optimizing the weights in the evaluation function when the c program
was somewhat slower, they weights are most suitable for 2C successors and by only using a depth of 6.
By searching deeper than this, the results actually get worse, while using our tuned weights.

The code functions by having a Qt4 GUI written in Python 2.7, which
manages the application window and a 2048 Widget that draws the board.
When the user presses play, a QThread worker object is initialized, which
manages the Expectimax search. It has a \emph{Play2048Player}, which keeps track of
\emph{Play2048State}s. After every move, it sends the board to the widget, which then draws it.
The state contains the board, represented as a \(List(16)\). Originally this
state inherited a generic \emph{AdversialSearchState}, but since the adversial
search in the final code is implemented entirely in C, this extra
genericity offered no benefit at all. The \emph{Play2048Player} has a search field, which
contains an instance of the class that is an implementation of an adversial search algorithm. This
search class only has to contain a \emph{decision(board)} method which takes a board
as an argument and returns a move representing the best possible action
given the current board.

In our final implementation, the search in \emph{Play2048Player} is an instance of
\emph{ExpectimaxC}. This is a simple proxy, which links to c .so-library and delegates
to the decision function implemented there. We had some interface issues between
C and Python, so the function signature in C is uglier than it should have to
be; taking each tile in the board as a separate argument.

\input{module_4/class_diagram}

\section{The heuristic}

The decision function in the C implementation uses ExpectiMax to find the best move.
The evaluation function used has implemented ideas of smoothness, the highest tile
on the current board, the amount of free tiles, the placement of the highest tile,
be in a corner, on an edge or in the middle, and the monotonicity of the board.
The constants in this equation can be supplied from the Python side, so we
could create a test runner in Python which ran the search supplying different
values for these constants.

\begin{equation}
	h = w_{smooth}  
\end{equation}

The two main ideas in this heuristic, aside from giving penalty to full board, and
misplaced high tiles are smoothness and monotonicity. Smoothness gives penalty
for the difference between neighbouring tiles. This means that neighbouring tiles
which are close in value are preferred to stay close together. The value of this is
that tiles can often be chained together in long tiles if we have for instance
1024, 512, 218 and 126 on the bottom row. Getting a new 126 above our existing 126
means we can get => 1024, 512, 218, 218 => 1024, 512, 512, x => 1024, 1024, x, x =>
2048, x, x, x. The smoother the board, the better the chance of this happening.

The other idea of monotonicity is checked on both the x-axis and the y-axis, and
the heuristic contributions of these are summed together. It checks that all the tiles
on both the x-axis and the y-axis are sorted. This also gives the advantage of
creating chains that can be merged together, and penalizes low tile values from
entering `behind' large tiles.

Removing the highest tile from a save corner, and having a low value get trapped
inside several large ones is the most common way of ending the game. Therefore
almost all our contributions to the heuristic focueses on this not happening.

\section{Improving the heuristic}

It is very easy to spot the difference between a bad heuristic and a good heuristic.
The good heuristic keeps the tiles sorted, especially around the highest tile around
the board, and makes good decisions for when to merge tiles into this sorted row.
However spotting the difference a decent heuristic and a slighly better one is not
easy by just running the program and trying to manually deduce a reasoning for why
it acts like it does. In the end, it is these small improvements that decide whether
we end up with 1024, 512, 256, but never manages to get the last 256 or whether
we find this last 256 and gets it merged together with the rest to create a 2048 tile.

To find these slight improvements we created a script that ran our program x amount of
times, and reported on the tiles achieved, average score and other metrics.

In the following run we have altered each constant by 0.9 and 1.1 and see if we
get different results. Each combination is run ten times. The original values
of smoothness = 0.2, max tile = 0.9, free tiles = 2.3, placement of max tile = 1.0
and monotonicity = 1.9 are the values we plan on using at the demo. We can se
that in this run, it actually achieves better than any small change to a constant.
However, 2048 is to random that 10 is a big enough sample size.

In the table the column names are shortened, their meanings are: "Smo.." => smoothness
constant, "Max" => max tile constant, "Free" => amount of free tiles constant,
"Pla.." => placement of max tile constant, "Mon.." => monotonicity constant. Avg is the
average score achieved, best is the best score. Scores around 10 000 achieved 1024,
scores around 25 000 - 35 000 achieved 2048 and score above 50 000 achieved 4096.
Worst is the worst score, and 2048s is the number of 2048s or above that was achieved.

\begin{center}
    \begin{tabular}{ | l | l | l | l | l | l | l | l | l | l | }
    \hline
    \# & Smo.. & Max & Free & Pla.. & Mon.. & Avg & Best & Worst & 2048s \\  \hline \hline
    1 & 0.2 & 0.9 & 2.3 &  1.0 & 1.9 & 28594.4 & 68256 & 7152 & 6 of 10 \\ \hline \hline
    2 & 0.18 & 0.9 & 2.3 &  1.0 & 1.9 & 20624.8 & 57324 & 5756 & 3 of 10 \\ \hline
    3 & 0.22 & 0.9 & 2.3 &  1.0 & 1.9 & 17192.8 & 36200 & 5464 & 3 of 10 \\ \hline
    4 & 0.2 & 0.81 & 2.3 &  1.0 & 1.9 & 21037.6 & 36792 & 14352 & 3 of 10 \\ \hline
    5 & 0.2 & 0.99 & 2.3 &  1.0 & 1.9 & 22116.8 & 35964 & 7368 & 4 of 10 \\ \hline
    6 & 0.2 & 0.9 & 2.07 &  1.0 & 1.9 & 15605.2 & 31704 & 6916 & 1 of 10 \\ \hline
    7 & 0.2 & 0.9 & 2.53 &  1.0 & 1.9 & 20782.0 & 37888 & 8016 & 3 of 10 \\ \hline
    8 & 0.2 & 0.9 & 2.3 &  0.9 & 1.9 & 20717.6 & 33848 & 11988 & 5 of 10 \\ \hline
    9 & 0.2 & 0.9 & 2.3 &  1.1 & 1.9 & 17720.4 & 35408 & 6160 & 2 of 10 \\ \hline
    10 & 0.2 & 0.9 & 2.3 &  1.0 & 1.71 & 19433.6 & 36316 & 7584 & 4 of 10 \\ \hline
    11 & 0.2 & 0.9 & 2.3 &  1.0 & 2.09 & 24885.6 & 37100 & 12900 & 6 of 10 \\ \hline
    \end{tabular}
\end{center}

We can see that highest score achieved was 68256, and the highest tile 4096. Below
is the score and tiles of each run of each of the above experiments. It is interesting
to note that while the original values score 2048 or above 6 times out of 10, 3 of the
remaining times it only achieves 512. While for instance run 4, where we lessen the
importance of the placement of the highest tile never achieves a 4096, but also always
achieves a 1024. In general it seems the heuristic must be willing to take some risk
to achieve the higher values. An heuristic that locks the highest tile in a corner
will give up good oppourtunities for merging tiles towards the middle and achieving
that higher tile. Often when one does achieve 2048 or 4096, the board is so barren,
that it is possible to navigate the new max back into a corner. But sometimes this
risk means that the max tile gets exposed in the middle and is unable to navigate back.

\begin{center}
    \begin{tabular}{ | l | l | l | l | l | l | l | l | l | l | l | }
    \hline
    \#1 & 8220 & 7824 & 32772 & 68256 & 16884 & 25392 & 7152 & 28084 & 32840 & 58520 \\  \hline
    \#1 & 512 & 512 & 2048 & 4096 & 1024 & 2048 & 512 & 2048 & 2048 & 4096 \\ \hline \hline
    \#2 & 9720 & 26572 & 15408 & 13848 & 57324 & 14916 & 34076 & 14412 & 14216 & 5756 \\ \hline
    \#2 & 1024 & 2048 & 1024 & 1024 & 4096 & 1024 & 2048 & 1024 & 1024 & 512 \\ \hline
    \#3 & 17096 & 15916 & 5464 & 23964 & 22496 & 7840 & 36200 & 14096 & 20056 & 8800 \\ \hline
    \#3 & 1024 & 1024 & 512 & 2048 & 2048 & 512 & 2048 & 1024 & 1024 & 512 \\ \hline
    \#4 & 14836 & 16132 & 17964 & 18152 & 36792 & 22524 & 17508 & 14352 & 18176 & 33940 \\ \hline
    \#4 & 1024 & 1024 & 1024 & 1024 & 2048 & 2048 & 1024 & 1024 & 1024 & 2048 \\ \hline
    \#5 & 18416 & 35964 & 33276 & 17336 & 14860 & 32820 & 13044 & 15804 & 7368 & 322808 \\ \hline
    \#5 & 1024 & 2048 & 2048 & 1024 & 1024 & 2048 & 1024 & 1024 & 512 & 2048 \\ \hline
    \#6 & 6916 & 18344 & 15220 & 8788 & 12064 & 11492 & 14560 & 22504 & 31704 & 14460 \\ \hline
    \#6 & 512 & 1024 & 1024 & 512 & 1024 & 1024 & 1024 & 1024 & 2048 & 1024 \\ \hline
    \#7 & 28732 & 19996 & 16180 & 17880 & 8016 & 18456 & 33072 & 37888 & 12180 & 15420 \\ \hline
    \#7 & 2048 & 1024 & 1024 & 1024 & 512 & 1024 & 2048 & 2048 & 1024 & 1024 \\ \hline
    \#8 & 33848 & 24928 & 16164 & 14952 & 26484 & 12552 & 26960 & 23116 & 11988 & 16184 \\ \hline
    \#8 & 2048 & 2048 & 1024 & 1024 & 2048 & 1024 & 2048 & 2048 & 1024 & 1024 \\ \hline
    \#9 & 20416 & 35408 & 28604 & 17048 & 6160 & 16424 & 7328 & 14188 & 15864 & 15764 \\ \hline
    \#9 & 1024 & 2048 & 2048 & 1024 & 512 & 1024 & 512 & 1024 & 1024 & 1024 \\ \hline
    \#10 & 36316 & 24572 & 30488 & 7584 & 11944 & 17716 & 12884 & 20236 & 7800 & 24796 \\ \hline
    \#10 & 2048 & 2048 & 2048 & 512 & 1024 & 1024 & 1024 & 1024 & 512 & 2048 \\ \hline
    \#11 & 28248 & 16304 & 23596 & 15768 & 17652 & 37100 & 35160 & 30624 & 12900 & 31504 \\ \hline
    \#11 & 2048 & 1024 & 2048 & 1024 & 1024 & 2048 & 2048 & 2048 & 1024 & 2048 \\ \hline
    \end{tabular}
\end{center}

Of course using entirely different values can also give good results, and changing one
constant must lead to a reevaluation of the others in relation. For instance multiplying
the monotonicity constant with 10 also gave good results:

Smoothness: 0.2, Max tile: 0.9, Free tiles: 2.3 Max placement: 1.0, Monotonicity: 19.0
Average score: 17601.0, Best: 32264, worst: 5720
All scores: [13308, 30488, 31324, 14556, 32264, 16140, 15320, 12456, 26748, 7996, 10748, 16428, 23344, 16256, 27184, 25072, 6852, 7760, 12056, 5720]
Max tiles: [1024, 2048, 2048, 1024, 2048, 1024, 1024, 1024, 2048, 512, 1024, 1024, 2048, 1024, 2048, 2048, 512, 512, 1024, 512]
2048s: 7 of 20

While multiplying the max placement constant gave awful results:
Smoothness: 0.2, Max tile: 0.9, Free tiles: 2.3, Max placement: 10.0, Monotonicity: 1.9
Average score: 10750.0, Best: 23600, worst: 2652
All scores: [10448, 13732, 5552, 6448, 16160, 4716, 15280, 11408, 7180, 10628, 3564, 16108, 3260, 14680, 2652, 16452, 23600, 3808, 15424, 13900]
Max tiles: [1024, 1024, 512, 512, 1024, 512, 1024, 1024, 512, 1024, 256, 1024, 256, 1024, 256, 1024, 2048, 256, 1024, 1024]
2048s: 1 of 20
